好的集成学习要求基学习器“好而不同”，因此理论上集成中的个体学习器应该相互独立(实际中，独立无法做到，但可以设法让基学习器尽可能有较大差异)。那一个很自然的想法就是对训练样本进行采样，产生若干个不同的子集，再从每个数据子集中训练出一个基学习器。这样由于训练数据不同, 获得的基学习器理论上是有比较大的差异的。但是另一方面，为了获得好的集成，我们还希望个体学习器不要太差，如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。为解决这个问题，可以考虑使用相互有交叠的采样子集(自助法采样)

bagging算法步骤：  
输入为样本集$D=\{(x_1,y_1), ..., (x_m,y_m)\}$, 弱分类器算法G，弱分类器迭代次数T。输出最终的强分类器$f(x)$  
1. 对于t=1，2，...，T：(a) 对训练集进行第t次有放回随机采样，采集m次，得到包含m个样本的采样集$D_t$。(b) 用采样集$D_t$训练第t个弱学习器$G_t(x)$
2. 如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。  

-------

随机森林：  
随机森林使用了CART决策树作为弱学习器。另外，随机森林的决策树，对基决策树的每个节点，先从该节点的属性集合S中随机选择一个包含k个属性的子集，再从该子集中选择一个最优属性进行划分。如果集合S=s，那此时随机森林的CART决策树和普通的CART决策树没有区别。这么做的原因是为了增加模型的泛化能力，一般来说s集合越小，模型的方差越小，但偏差越大。  
因此在随机森林中，基学习器的差异化不仅体现在靠自助法产生的样本差异，还有选择分裂属性上的随机性。
算法步骤：
输入为样本集$D=\{(x_1,y_1), ..., (x_m,y_m)\}$, 弱分类器迭代次数T。输出最终的强分类器$f(x)$  
1. 对于t=1，2，...，T：(a) 对训练集进行第t次有放回随机采样，采集m次，得到包含m个样本的采样集$D_t$。(b) 用采样集$D_t$训练第t个决策树模型$G_t(x)$，在训练决策树模型的节点的时候， 在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分。
2. 如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。  

----
模型评估方法：  
---
基本思想：将原始数据（dataset）进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。  
通过评估模型的预测性能，可以选择最好的模型(包括模型算法和模型参数)。另外如果有验证集，可以在训练时用于防止过拟合(比如辅助决策树剪枝、及早停止神经网络训练等)。  

1. 留出法：在机器学习任务中，拿到数据后，我们首先会将原始数据集分为三部分：训练集、验证集和测试集。训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。  
   不过如果只做一次分割，它对训练集、验证集、测试集的样本数比例，还有三个集合的数据是否是同分布等因素比较敏感，不同的划分可能会得到不同的最优模型。而且分成三个集合后，对于小数据集而言用于训练的数据更少了。

2. k折交叉验证：把数据集D划分为k个大小相似的互斥子集$D_i$,每个子集都尽量保持数据分布一致(可以通过分层采样得到)。然后每次用k-1个子集的并集作为训练集，余下的子集作为测试集，训练k个模型并获得这k个模型在对应测试集上的误差，最终该模型(即包括对应算法和配套的超参数)的误差就是k个误差的平均值。  
   为了减少因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终评估结果是这p次k折交叉验证结果的均值。  
   获取最好的模型设置后(对应算法和配套的超参数)，可以把所有样本当做训练集，重新训练出一个最终的模型出来。

3. 自助法：给定包含m个样本的数据集D，对其进行有放回采样m次，生成训练样本集$D'$。一个样本在m次采样中始终不被采到的概率是$(1-\frac{1}{m})^m$,取极限的值大约为0.368。也就是说通过自助采样，实际评估的模型和期望评估的模型都使用m个训练样本，而我们可以使用大约1/3没被采样到的样本作为测试集(或验证集)。  
   优点：自助法在数据集较小，难以有效划分训练/测试集时很有用。另外自助法能从初始数据集中产生多个不同的训练集，这对集成学习有很大好处。缺点：自助法产生的数据集改变了原始数据集分布，引入了估计偏差。因此在数据量足够的情况下，使用留出法和交叉验证法更好点。
