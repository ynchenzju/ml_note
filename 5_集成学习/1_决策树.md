1. 熵：表示随机变量不确定性的度量。假设X是一个取有限个值的离散随机变量，概率分布为  
   $$P(X=x_i)=p_i, i=1,2,...,n$$  
   则随机变量X的熵定义为    
   $$H(X)=-\sum_i^np_ilnp_i$$
   其中若$p_i=0$，定义$0ln0=0$。
2. 用特征A对训练数据集D进行划分得到的信息增益=经验熵-经验条件熵  
   $$g(D,A)=H(D)-H(D|A)$$
3. 使用信息增益作为划分训练数据集的特征，存在于偏向于选择取值较多的特征的问题。使用信息增益比对这个问题进行校正：特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益比$g(D,A)$与训练数据集D关于特征A的值的熵$H_A(D)$之比，即  
   $$g_R(D,A)=\frac{D,A}{H_A(D)}$$  
   其中  
   $$H_A(D)=-\sum_{i=1}^n\frac{|D_i|}{D}ln\frac{|D_i|}{D}$$  
   n是特征A取值的个数

4. 决策树算法：ID3使用信息增益进行训练，C4.5使用信息增益比进行训练。具体可以例子可以看https://zhuanlan.zhihu.com/p/26760551  

-----

对于决策树算法中，一个特征能否重复使用(放回)的思考：  
---
首先描述一下C4.5算法：  
输入：训练数据集D，特征集A，阈值$\epsilon$  
输出：决策树T  
(1) 如果D中所有实例都属于同一类$C_k$, 则置T为单节点树，并将$C_k$作为该节点的类，返回T。  
(2) 如果$A=\emptyset$, 则置T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类，返回T。  
(3) 否则，计算A中各特征对D的信息增益比，选择信息增益比最大的特征$A_g$。  
(4) 如果$A_g$的信息增益比小于阈值$\epsilon$，则置T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类，返回T。  
(5) 否则，对$A_g$的<font color=red>所有</font>可能值$a_i$，按照$A_g=a_i$将D分割为子集若干非空$D_i$，将$D_i$中实例数最大的类作为标记，构建子节点，由节点和其子节点构成树T，返回T。  
(6) 对节点i，以$D_i$为训练集，以$A-\{A_g\}$为特征集，递归调用(1)-(5)，得到子树$T_i$，返回$T_i$  

注意该算法中每次是利用一个特征的“所有”可能值，对节点进行迭代划分。也就是说这里包含几个意思：  
(1) 该特征取值是离散的(或者说可以按照某种方式将连续值作离散化)。  
(2) 每次利用该特征分裂子节点时，是利用该特征的所有可能值生成多叉树。  
这样，一个特征就可以说是被利用完全了，后续该特征在子树生成上就没有价值了。因此，这个算法里后续是从$A-\{A_g\}$中取特征，特征不放回。  
因此如果特征不满足以上两个条件，也就是说，如果特征取值是连续的(无法枚举)，或者每次利用该特征分裂子节点时，只是利用该特征的部分可能值生成多叉树，那么后续利用该特征可能仍然有信息增益比上的收益，因此在这种情况下，该特征是可以放回的。  
或者说，不存在一个特征能否放回的问题，而是一个特征有没有使用完全的问题。

---

CART算法，如果建立回归树, 则我们有n个训练样本$\{(X_1,y_1), ..., (X_n, y_n)\}$，其中$X_i=(x_i^1, ..., x_i^m)$，CART是二叉树，每一次分裂都是在求以下式子：  
   $$min_{(j,s)}\{min_{c_1}\sum_{X_i\in R_1(j,s)}||y_i-c_1||^p+min_{c_2}\sum_{X_i\in R_2(j,s)}||y_i-c_2||^p\}$$  
   $||\cdot ||^p$表示p范数  
1. 遍历变量j，对固定的切分变量j扫描切分点s。因此生成一组切分变量和扫描点集合$\{(j_{p_1},s_{q_1})\}$
2. 对每一对(j,s)划分区域：  
   $$R_1(j_{p_1},s_{q_1})=\{X_k|x_k^{j_{p_1}}\leq s_{q_1}\}, R_2(j_{p_1},s_{q_1})=\{X_k|x_k^{j_{p_1}}\gt s_{q_1}\}$$  
   求$c_1, c_2$, 以计算  
   $$v=min_{c_1}\sum_{X_i\in R_1(j_{p_1},s_{q_1})}||y_i-c_1||^p+min_{c_2}\sum_{X_i\in R_2(j_{p_1},s_{q_1})}||y_i-c_2||^p$$  
   记录$\{(j_{p_1},s_{q_1},c_1,c_2,v)\}$  
   选择v最小时的$(j_{p_1}, s_{q_1},c_1,c_2)$，那么$(j_{p1}, s_{q_1})$就是此次的切分变量和切分点，$c_1,c_2$就是这两个子节点的输出。特别的，当p=2时，$c_m=\frac{1}{N_m}\sum_{X_i\in R_m(j,s)}y_i$，其中$m=1,2$ 
3. 继续对两个子区域调用步骤1，2，直到满足停止条件。
4. 输入空间被划分为了M个区域$R_1, R_2, ..., R_M$,生成决策树：  
   $$f(x)=\sum_{m=1}^Mc_mI(x\in R_m)$$